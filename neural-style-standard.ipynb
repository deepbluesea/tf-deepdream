{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Copyright (c) 2015-2016 Anish Athalye. Released under GPLv3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boilerplate code\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import math\n",
    "\n",
    "import time\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "try:\n",
    "    reduce\n",
    "except NameError:\n",
    "    from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Net Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_net(data_path, input_image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    data = scipy.io.loadmat(data_path)\n",
    "    mean = data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "    weights = data['layers'][0]\n",
    "\n",
    "    net = {}\n",
    "    current = input_image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = np.transpose(kernels, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            current = _conv_layer(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current)\n",
    "        elif kind == 'pool':\n",
    "            current = _pool_layer(current)\n",
    "        net[name] = current\n",
    "\n",
    "    assert len(net) == len(layers)\n",
    "    return net, mean_pixel\n",
    "\n",
    "\n",
    "def _conv_layer(input, weights, bias):\n",
    "    conv = tf.nn.conv2d(input, tf.constant(weights), strides=(1, 1, 1, 1),\n",
    "            padding='SAME')\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "\n",
    "def _pool_layer(input):\n",
    "    return tf.nn.max_pool(input, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1),\n",
    "            padding='SAME')\n",
    "\n",
    "\n",
    "def preprocess(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "\n",
    "def unprocess(image, mean_pixel):\n",
    "    return image + mean_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stylize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONTENT_LAYER = 'conv4_2'\n",
    "STYLE_LAYERS = ('conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1')\n",
    "\n",
    "def stylize(network, initial, content, styles, iterations,\n",
    "        content_weight, style_weight, style_blend_weights, tv_weight,\n",
    "        learning_rate, print_iterations=None, checkpoint_iterations=None):\n",
    "    \"\"\"\n",
    "    Stylize images.\n",
    "    This function yields tuples (iteration, image); `iteration` is None\n",
    "    if this is the final image (the last iteration).  Other tuples are yielded\n",
    "    every `checkpoint_iterations` iterations.\n",
    "    :rtype: iterator[tuple[int|None,image]]\n",
    "    \"\"\"\n",
    "    shape = (1,) + content.shape\n",
    "    style_shapes = [(1,) + style.shape for style in styles]\n",
    "    content_features = {}\n",
    "    style_features = [{} for _ in styles]\n",
    "\n",
    "    # compute content features in feedforward mode\n",
    "    print('Computing forward pass for content features...', end='')\n",
    "    g = tf.Graph()\n",
    "    with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "        image = tf.placeholder('float', shape=shape)\n",
    "        net, mean_pixel = run_net(network, image)\n",
    "        content_pre = np.array([preprocess(content, mean_pixel)])\n",
    "        content_features[CONTENT_LAYER] = net[CONTENT_LAYER].eval(\n",
    "                feed_dict={image: content_pre})\n",
    "    print('Done!')\n",
    "\n",
    "    # compute style features in feedforward mode\n",
    "    print('Computing forward pass for style features...', end='')\n",
    "    for i in range(len(styles)):\n",
    "        g = tf.Graph()\n",
    "        with g.as_default(), g.device('/cpu:0'), tf.Session() as sess:\n",
    "            image = tf.placeholder('float', shape=style_shapes[i])\n",
    "            net, _ = run_net(network, image)\n",
    "            style_pre = np.array([preprocess(styles[i], mean_pixel)])\n",
    "            for layer in STYLE_LAYERS:\n",
    "                features = net[layer].eval(feed_dict={image: style_pre})\n",
    "                features = np.reshape(features, (-1, features.shape[3]))\n",
    "                gram = np.matmul(features.T, features) / features.size\n",
    "                style_features[i][layer] = gram\n",
    "    print('Done!')\n",
    "\n",
    "    # make stylized image using backpropogation\n",
    "    with tf.Graph().as_default():\n",
    "        if initial is None:\n",
    "            noise = np.random.normal(size=shape, scale=np.std(content) * 0.1)\n",
    "            initial = tf.random_normal(shape) * 0.256\n",
    "        else:\n",
    "            initial = np.array([preprocess(initial, mean_pixel)])\n",
    "            initial = initial.astype('float32')\n",
    "        image = tf.Variable(initial)\n",
    "        net, _ = run_net(network, image)\n",
    "\n",
    "        # content loss\n",
    "        content_loss = content_weight * (2 * tf.nn.l2_loss(\n",
    "                net[CONTENT_LAYER] - content_features[CONTENT_LAYER]) /\n",
    "                content_features[CONTENT_LAYER].size)\n",
    "        \n",
    "        # style loss\n",
    "        style_loss = 0\n",
    "        for i in range(len(styles)):\n",
    "            style_losses = []\n",
    "            for style_layer in STYLE_LAYERS:\n",
    "                layer = net[style_layer]\n",
    "                _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "                size = height * width * number\n",
    "                feats = tf.reshape(layer, (-1, number))\n",
    "                gram = tf.matmul(tf.transpose(feats), feats) / size\n",
    "                style_gram = style_features[i][style_layer]\n",
    "                style_losses.append(2 * tf.nn.l2_loss(gram - style_gram) / style_gram.size)\n",
    "            style_loss += style_weight * style_blend_weights[i] * reduce(tf.add, style_losses)\n",
    "            \n",
    "        # total variation denoising\n",
    "        if tv_weight > 0:\n",
    "            tv_y_size = _tensor_size(image[:,1:,:,:])\n",
    "            tv_x_size = _tensor_size(image[:,:,1:,:])\n",
    "            tv_loss = tv_weight * 2 * (\n",
    "                    (tf.nn.l2_loss(image[:,1:,:,:] - image[:,:shape[1]-1,:,:]) /\n",
    "                        tv_y_size) +\n",
    "                    (tf.nn.l2_loss(image[:,:,1:,:] - image[:,:,:shape[2]-1,:]) /\n",
    "                        tv_x_size))\n",
    "            # overall loss\n",
    "            loss = content_loss + style_loss + tv_loss\n",
    "        else:\n",
    "            # overall loss\n",
    "            loss = content_loss + style_loss\n",
    "            tv_loss = 0\n",
    "\n",
    "        # optimizer setup\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "        def print_progress(i, last=False):\n",
    "            print('\\rIteration %d/%d' % (i + 1, iterations))\n",
    "            if print_iterations and i % print_iterations == 0:\n",
    "                print('  content loss: %g\\n' % content_loss.eval())\n",
    "                print('    style loss: %g\\n' % style_loss.eval())\n",
    "                print('       tv loss: %g\\n' % tv_loss.eval())\n",
    "                print('    total loss: %g\\n' % loss.eval())\n",
    "\n",
    "        # optimization\n",
    "        best_loss = float('inf')\n",
    "        best = None\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            for i in range(iterations):\n",
    "                last_step = (i == iterations - 1)\n",
    "                print_progress(i, last=last_step)\n",
    "                train_step.run()\n",
    "\n",
    "                if (checkpoint_iterations and i % checkpoint_iterations == 0) or last_step:\n",
    "                    this_loss = loss.eval()\n",
    "                    if this_loss < best_loss:\n",
    "                        best_loss = this_loss\n",
    "                        best = image.eval()\n",
    "                    yield (\n",
    "                        (None if last_step else i),\n",
    "                        unprocess(best.reshape(shape[1:]), mean_pixel)\n",
    "                    )\n",
    "\n",
    "def _tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "    # create an empty (?) file object\n",
    "    f = BytesIO()\n",
    "    # save array to file object\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "# Helper functions that use TF to resize an image\n",
    "def tffunc(*argtypes):\n",
    "    '''Helper that transforms TF-graph generating function into a regular one.\n",
    "    See \"resize\" function below.\n",
    "    '''\n",
    "    placeholders = list(map(tf.placeholder, argtypes))\n",
    "    def wrap(f):\n",
    "        out = f(*placeholders)\n",
    "        def wrapper(*args, **kw):\n",
    "            return out.eval(dict(zip(placeholders, args)), session=kw.get('session'))\n",
    "        return wrapper\n",
    "    return wrap\n",
    "\n",
    "def resize(img, size):\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    return tf.image.resize_bilinear(img, size)[0,:,:,:]\n",
    "resize = tffunc(np.float32, np.int32)(resize)\n",
    "\n",
    "def stdize(a, s=0.1):\n",
    "    '''Normalize the image range for visualization'''\n",
    "    return (a-a.mean())/max(a.std(), 1e-4)*s + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing forward pass for content features...Done!\n",
      "Computing forward pass for style features...Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 1000/1000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed: 1148 seconds\n"
     ]
    }
   ],
   "source": [
    "# default arguments\n",
    "CONTENT_WEIGHT = 5e0\n",
    "STYLE_WEIGHT = 1e0 #1e2\n",
    "TV_WEIGHT = 1e2\n",
    "LEARNING_RATE = 1e1\n",
    "STYLE_SCALE = 1.0\n",
    "ITERATIONS = 1000\n",
    "\n",
    "saving = 1\n",
    "NETWORK_LOC = '/media/data/Dropbox/Git/tf-deepdream/imagenet-vgg-verydeep-19.mat'\n",
    "# CONTENT_LOC = '/media/data/Dropbox/image-play/source/snow/sierra_in_snow.jpg'\n",
    "CONTENT_LOC = '/media/data/Dropbox/image-play/source/buildings/hong_kong_0.jpg'\n",
    "STYLE_LOC = '/media/data/Dropbox/image-play/source/art/starry_night.jpg'\n",
    "OUTPUT_LOC = '/media/data/Dropbox/image-play/ns-single_image/hong_kong_skyline'\n",
    "\n",
    "PRINT_ITERATIONS = None\n",
    "CHECKPOINT_ITERATIONS = None\n",
    "\n",
    "# import images\n",
    "content_image = np.float32(PIL.Image.open(CONTENT_LOC))\n",
    "style_image = np.float32(PIL.Image.open(STYLE_LOC))\n",
    "target_shape = content_image.shape\n",
    "img0 = np.random.randn(*target_shape)\n",
    "\n",
    "start = time.time()\n",
    "for iteration, image in stylize(\n",
    "    network=NETWORK_LOC,\n",
    "    initial=img0,\n",
    "    content=content_image,\n",
    "    styles=[style_image],\n",
    "    iterations=ITERATIONS,\n",
    "    content_weight=CONTENT_WEIGHT,\n",
    "    style_weight=STYLE_WEIGHT,\n",
    "    style_blend_weights=[1],\n",
    "    tv_weight=TV_WEIGHT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    print_iterations=PRINT_ITERATIONS,\n",
    "    checkpoint_iterations=CHECKPOINT_ITERATIONS\n",
    "):\n",
    "    if (iteration is None) and saving:\n",
    "        file_name = 'hong_kong_1000_s1_c5_starrynight.jpg'\n",
    "        file_path = '/'.join([OUTPUT_LOC, file_name])\n",
    "        image = np.uint8(np.clip(image, 0, 255))\n",
    "        PIL.Image.fromarray(image).save(file_path, 'jpeg')\n",
    "end = time.time()\n",
    "\n",
    "print('Total time elapsed: %d seconds' % (end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
